---
layout: post
title: "Project: Data Cleaning"
date: 2023-12-05
---
## Introduction
At the onset of the COVID pandemic in 2020, many opted to stop traveling and there was a noticeable decline in airport travel. By 2022, airports seemed to be back to pre-pandemic business. I want to investigate 2022 statistics for the most popular airports in the United States.  

I created an extensive table for the top 200 ranked airports in the United States. Data for this ranked list was sourced from the Bureau of Transportation Statistics*1*. 

## Data Cleaning
In the file **DataCleaning.ipynb**, I cleaned and organized the data into a .cvs file.

I found a bunch of data from https://www.bts.gov/ and https://www.faa.gov/airports available for download. 

My goal with these data sets is to create columns I can merge together for my own data set. 

---

1. The first file I read was called ranking.xlsx and I previewed it.

**rankings** 
- U.S. Airports, ranked by 2022 Systemwide* Scheduled Enplanements Passenger numbers in millions (000,000)
- https://www.bts.gov/topics/airlines-and-airports/airport-rankings-2022

>> rankings = pd.read_excel(partialpath+'AirportRankings2022.xlsx')
>> rankings.head(3)
&emsp; From this table, I decided to only keep the first three columns: 
&emsp; 2022 Rank, Airport, & 2022 Enplaned Passengers. 

---

2. Next, I needed to add IATA codes for each airport. This will allow me to use API later to fetch more information for the data table. 

I used airportLOCID to create an index to replace the Airport column with IATA codes. 

**airportLOCID**   
    -  data sourced from https://www.faa.gov/data_research

>> airportLOCID = pd.read_excel(partialpath+'NPIAS-Report-2019-2023-Appendix-A.xlsx')
>> columns = ['LOCID', 'Airport','City','State']
>> cleanLOCID = pd.concat([airportLOCID['LOCID'], airportLOCID['Airport'],airportLOCID['City'],airportLOCID['State']],axis=1)

--- 

3. Then, I used data from rankings, originatingPassengers, & airportPassengersBoarded in a for-loop to create lists that will be used as columns. 

>> rankedAirports = rankings['Airport']
>> rankedAirportNames = rankedAirports.str.extract(r':\s*(.*)$')

>> rankedLOCID = []

>> for i in range(len(rankedAirportNames)):
>>     if rankedAirportNames[0][i] == 'Tri Cities WA':
>>         rankedLOCID += ['TRI'] # I ended up having to hard code this to fix an error.
>>     else:
>>         try:
>>             rankedLOCID += [cleanLOCID.loc[cleanLOCID['Airport'] == rankedAirportNames[0][i] , 'LOCID'].iloc[0]]
>>         except IndexError:
>>             rankedLOCID += [rankedAirportNames[0][i]]

>> rank = rankings['2022 Rank']
>> conversionfactor = 1000000
>> numPassengers = rankings['2022 Enplaned Passengers']*conversionfactor

---

4. At this point, the rankedLOCID was still missing values for some of the IATA codes, so I made a request from chatGPT to create a file with the known airport name to populate IATA codes. 

>> extraLOCID = pd.read_csv(partialpath+'extraLOCID.txt')

I created a new variable cleanedRankedLOCID that will fill in the rows that still have full Airport names instead of IATA code. 

>> cleanedRankedLOCID = rankedLOCID

>> for i in range(len(rankedLOCID)):
>>     if len(cleanedRankedLOCID[i]) > 3:
>>         temp = extraLOCID.loc[extraLOCID['Airport'] == rankedLOCID[i], 'LOCID'].iloc[0]
>>         cleanedRankedLOCID[i] = temp

---

4. Next, I combined rank, cleanedRankedLOCID (IATA vals), and numPassengers into a DataFrame. 

>> cleanRank = pd.concat([rank,pd.DataFrame(cleanedRankedLOCID),numPassengers],axis=1)
>> cleanRank.rename(columns={0: 'Airport'}, inplace=True)

I renamed this column of IATA codes *Airport* but I eventually change it IATA. 

---

5. After, I wanted to add more columns, so I used the DataFrame: originatingPassengers. 

**OriginatingPassengers**
- U.S. Airports ranked by 2022 Originating Domestic Passengers  
- Source: Bureau of Transportation Statistics, Origin & Destination Survey
- DB1B Ticket, Based on 10 Percent Ticket Sample
- O&D numbers are not comparable to T-100 Market Enplanement numbers

>> originatingPassengers = pd.read_excel(partialpath+'OriginatingPassengers.xlsx')

I noticed that originatingPassengers has a column for Code to match up to Airport(IATA Codes).
I used a for-loop to populate a vector with Originating Domestic Passengers for each specific row. 

>> cleanCodes = cleanRank['Airport']
>> ogDomPassengers = []
>> originatingPassengers.columns = originatingPassengers.columns.str.strip()

>> for i in range(len(cleanCodes)):
>>     if cleanCodes[i] == 'GPI':
>>         ogDomPassengers += [originatingPassengers.loc[originatingPassengers['Code'] == 'FCA' , 'Originating Domestic Passengers'].iloc[0]]
>>     else:
>>         ogDomPassengers += [originatingPassengers.loc[originatingPassengers['Code'] == cleanCodes[i] , 'Originating Domestic Passengers'].iloc[0]]

--- 

6. Next, I added the new column to my DataFrame. 

>> cleanedData = pd.concat([cleanRank, pd.DataFrame(ogDomPassengers)],axis=1)
>> cleanedData.rename(columns={0: '2022 Originating Domestic Passengers'}, inplace=True)

---

7. Now that my table has 4 solid columnns, *2022 Rank*,	*Airport*, *2022 Enplaned Passengers*, & *2022 Originating Domestic Passengers*, I knew I wanted more information and decided to use API to request ICAO codes. 

After reading in my API key to a variable called: apiKey, I used it to request al the ICAO codes.   
I encountered a couple of errors in trying to do this because of issues with my ICAO codes.   
To remedy this easily, I just hard coded for the airports that kept having issues. 

>> base_url = "https://aviation-reference-data.p.rapidapi.com/airports/"
>> endpoints = cleanedData['Airport']

>> cleanedICAO = [['IATA','ICAO']]

>> for i in range(len(endpoints)):
>>     if endpoints[i].strip() == 'GPI': # Glacier Park International
>>         icao = 'KGPI'
>>         iata = 'GPI'
>>     if endpoints[i].strip() == 'VPS': # Eglin AFB Destin Fort Walton Beach
>>         icao = 'KVPS'
>>         iata = 'VPS'
>>     else:
>>         url = base_url + endpoints[i].strip()
>>         headers = {"X-RapidAPI-Key": apiKey,
>>         "X-RapidAPI-Host": "aviation-reference-data.p.rapidapi.com"}         
>>         r = requests.get(url, headers=headers)
>>         icao = r.json()['icaoCode']
>>         iata = r.json()['iataCode']
>>     cleanedICAO += [[iata,icao]]

I cleaned up the DataFrame of ICAO and IATA codes so that I can merge it with my main DataFrame. 

>> icaoDF = pd.DataFrame(cleanedICAO[1:], columns=cleanedICAO[0])    

>> cleanedData = pd.merge(cleanedData, icaoDF[['IATA', 'ICAO']], left_on='Airport', right_on='IATA', how='left')
>> cleanedData = cleanedData.drop('IATA', axis=1)

--- 

8. In reviewing my table, I realized there are some null values that I want to take care of.
- Airport *GPI* is Glacier Park International Airport, which has 2 codes: GPI and FCA. 
- I need to update it from GPI to FCA in order for the merge on airportStats to work correctly. 
- Since I added in safety measures in previous loops & chunks for GPI before I updated it here, the information will all be correct, regardless. 

No matter how hard I tried, I could not fix the GPI/FCA Glacier vs. Guapi Airport issue, so I just hard coded it in the end. 

>> cleanedData['Airport'] = cleanedData['Airport'].replace('GPI', 'FCA')
>> cleanedData.loc[cleanedData['Airport'] == 'FCA', 'ICAO'] = 'KGPI'

---

9. Then, I used a secondary API to populate Longitude, Lattitude, Elevation, and State columns. 

After reading in the API token to a variable called: apiToken, I used it add the specific columns I wanted. 

I created a new DataFrame called airportDF to hold all the information from this API request. 

>> url_template = "https://airportdb.io/api/v1/airport/{ICAO}?apiToken={apiToken}"
>> icao = cleanedData['ICAO']

>> airportDF = pd.DataFrame()

>> for i in range(len(icao)):
>>     url = url_template.format(ICAO=icao[i], apiToken=apiToken)
>>     r = requests.get(url)
>>     if i == 0:
>>         airportDF = pd.json_normalize(r.json())
>>     else:
>>         airportDF = pd.concat([airportDF, pd.json_normalize(r.json())],axis=0)

>> airportDF.reset_index(drop=True, inplace=True)

--- 

10. After I created the airportDF from the API request, I merged on the new columns I wanted to my exisiting DataFrame. 

>> cleanDF = pd.merge(cleanedData, airportDF[['iata_code', 'icao_code', 'name', 'latitude_deg', 'longitude_deg', 'elevation_ft', 'region.name']], left_on='ICAO', right_on='icao_code', how='left')
>> cleanDF.reset_index(drop=True, inplace=True)

--- 

11. Next, I cleaned up my main DataFrame and renamed the columns. 

>> cleanDF = cleanDF.drop('iata_code', axis=1)
>> cleanDF = cleanDF.drop('icao_code', axis=1)
>> cleanDF.rename(columns={'Airport': 'IATA'}, inplace=True)
>> cleanDF.rename(columns={'latitude_deg': 'Latitude', 
                        'longitude_deg': 'Longitude', 
                        'elevation_ft': 'Elevation', 
                        'region.name': 'State',
                        'name': 'Airport'}, inplace=True)

--- 

12. I was happy with the DataFrame, but I wanted to add more interesting information about each airport. 
After searching online for available data, I found this website: https://www.stratosjets.com/blog/us-airport-rankings/ with an updated 2022 table of US airports and for each...  
- Flights Per Year	
- Delays %	
- Canceled %	
- Avg. Delay (Mins)	
- Security Delay (Mins)

I copied the data into a .txt file named: AirportStats.txt. 

>> airportStats = pd.read_csv(partialpath+'AirportStats.txt',sep="\t")

I merged the airportStats with cleanDF to create a new table, finalDF.

>> finalDF = pd.merge(cleanDF, airportStats[['Code', 'Flights Per Year', 'Delays %', 'Canceled %', 'Avg. Delay (Mins)', 'Security Delay (Mins)']], left_on='IATA', right_on='Code', how='left')

---

13. Then, I did some cleaning and organization to the finalDF DataFame

>> finalDF = finalDF.drop('Code', axis=1)
>> finalDF['Delays %'] = finalDF['Delays %'] / 100
>> finalDF['Canceled %'] = finalDF['Canceled %'] / 100
>> columnOrder = ['2022 Rank', 'Airport', 'IATA', 'ICAO', '2022 Enplaned Passengers', 
>>                '2022 Originating Domestic Passengers', 'Flights Per Year', 'Delays %', 
>>                'Canceled %', 'Avg. Delay (Mins)', 'Security Delay (Mins)', 'Latitude', 
>>                'Longitude', 'State', 'Elevation']
>> finalDF = finalDF[columnOrder]
>> finalDF.rename(columns={'Delays %': 'Delays', 'Canceled %': 'Canceled'}, inplace=True)

---

14. Upon previewing the finalDF DataFrame, I realized it was 203 rows long, which is too many. I cleaned for the duplicats in this step. 

>> finalDF.drop_duplicates(subset=['IATA'], keep='first', inplace=True, ignore_index=True)

---

15. Finally, I exported my DataFrame to a .csv file for data visualization. 

>> finalDF.to_csv('2022Airports.csv', index=False)

---

**Note:** I use the variable *partialpath* throughout to refer to the folder location with my stored data sets. All of this can be viewed at: https://github.com/lucystorts/386Project 






before I exported my DataFrame to a .csv file. 

- The ranked list file that was read into python needed to be cleaned. 
- I cleaned it using a LOCID table*2* and a supplementary LOCID table*3*. 
- Next, I added originating*4* and enplaned*5* passenger data for each airport. 
- Then, I used rapidAPI*6* to get ICAO codes for each row.
- Next, I used a second API*7* and the ICAO values to get long, lat, etc. columns. 
- Last, I found a blog*8* that compiled an updated table of US airports for 2020 and interesting statistics. I accessed the table as a text file and merged it onto my pandas DataFrame. 
- I exported my dataframe to 2022Airports.csv. 

